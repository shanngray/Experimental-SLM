# Custom Transformer Configuration
# This config uses the default custom Transformer architecture.
# Set model_name to null or omit it to use custom Transformer.

# ============================================================================
# Model Selection
# ============================================================================
# Set to null to use custom Transformer architecture
model_name: null  # null = use custom Transformer with architecture params below

# ============================================================================
# Model Architecture Hyperparameters
# ============================================================================
# These are only used when model_name is null (custom Transformer)
n_layers: 4
d_model: 256
n_heads: 4
d_ff: 1024
dropout: 0.1

# ============================================================================
# Dataset Hyperparameters
# ============================================================================
train_ratio: 0.95
max_seq_len: 256

# ============================================================================
# Training Loop Hyperparameters
# ============================================================================
max_steps: 10000
checkpoint_cadence: 1000

# ============================================================================
# Optimizer Hyperparameters
# ============================================================================
learning_rate: 3.0e-4
weight_decay: 0.1
beta1: 0.9
beta2: 0.95
batch_size: 16

# ============================================================================
# Evaluation and Sampling Hyperparameters
# ============================================================================
eval_cadence: null
sampling_cadence: null
sampling_temperature: 1.0
sampling_prompt: "The"
sampling_max_length: 100
sampling_seed: 42

# ============================================================================
# Other Hyperparameters
# ============================================================================
seed: null
hooks: null

# ============================================================================
# Quantization Hyperparameters
# ============================================================================
quantization_mode: null
quantization_bits: 8
quantization_type: "static"
enable_quantized_finetuning: false

# ============================================================================
# Notes
# ============================================================================
# - When model_name is null, architecture hyperparameters (n_layers, d_model, etc.)
#   are used to create a custom Transformer from scratch.
# - To use an imported model instead, set model_name to a value from the registry.

