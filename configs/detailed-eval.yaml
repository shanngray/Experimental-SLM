# Detailed Evaluation Configuration
# This configuration enables frequent evaluation and sampling during training.
# Use this when you want to closely monitor training progress and see how
# the model improves over time.
#
# Trade-offs:
# - Better visibility into training progress
# - More frequent model outputs to inspect
# - Slower training due to evaluation overhead
# - Useful for debugging and understanding model behavior

# Model Architecture - Default size
n_layers: 4
d_model: 256
n_heads: 4
d_ff: 1024
dropout: 0.1

# Dataset
train_ratio: 0.95
max_seq_len: 256

# Training Loop
max_steps: 10000
checkpoint_cadence: 1000

# Optimizer
learning_rate: 3.0e-4
weight_decay: 0.1
beta1: 0.9
beta2: 0.95
batch_size: 16

# Evaluation and Sampling - More frequent
eval_cadence: 500  # Evaluate every 500 steps (more frequent than default)
sampling_cadence: 500  # Sample every 500 steps (more frequent than default)
sampling_temperature: 1.0
sampling_prompt: "The"
sampling_max_length: 100
sampling_seed: 42

# Other
seed: null
hooks: null

